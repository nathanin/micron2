{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ingn/devel/micron2/micron2/clustering/utils.py:16: UserWarning: Failed to import GPU tools. Accelerated neighbors/leiden/t-SNE/UMAP will not be unavailable\n",
      "  warnings.warn('Failed to import GPU tools. Accelerated neighbors/leiden/t-SNE/UMAP will not be unavailable')\n",
      "/home/ingn/devel/micron2/micron2/spatial/utils.py:11: UserWarning: Failed to load RAPIDS cuda-enabled tools.\n",
      "  warnings.warn(\"Failed to load RAPIDS cuda-enabled tools.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from micron2.clustering import Encoder, train_moco\n",
    "from micron2.data import stream_dataset\n",
    "\n",
    "import h5py\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined_dataset.hdf5  moco  moco-cells\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ingn/tmp/micron2-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1q', 'CD103', 'CD11c', 'CD134', 'CD138', 'CD20', 'CD31', 'CD3e', 'CD4', 'CD40', 'CD40LG', 'CD45', 'CD45RA', 'CD45RO', 'CD64', 'CD68', 'CD69', 'CD8', 'CD80', 'CD89', 'CXCL13', 'CXCR5', 'DAPI', 'FOXP3', 'GZMB', 'HLA-DR', 'IL7R', 'IgA', 'IgG', 'IgM', 'Ki-67', 'LAG3', 'OX40L', 'PD-1', 'PD-L1', 'PDGFRb', 'PNaD', 'PanCytoK', 'TIM3', 'aSMA']\n",
      "tf.Tensor(\n",
      "[4.03521284e-02 1.56009267e-03 3.80972982e-03 7.41325028e-04\n",
      " 2.18258538e-06 2.94799940e-03 8.33688420e-04 1.31129893e-02\n",
      " 3.91811766e-02 1.51037591e-06 7.50164734e-04 1.13088422e-01\n",
      " 5.24967210e-04 1.45652157e-05 1.02015865e-05 2.21496403e-01\n",
      " 3.46743298e-04 1.77023932e-02 3.68218054e-04 8.11160426e-04\n",
      " 2.60041095e-02 9.20398361e-06 1.50515575e+01 3.63372010e-03\n",
      " 9.30123380e-04 1.49623051e-01 1.15755902e-05 1.52418797e-03\n",
      " 2.97930002e-01 9.33473289e-04 2.34060502e-03 5.37125743e-04\n",
      " 1.70752604e-03 2.24937452e-03 3.98730799e-06 4.62812051e-04\n",
      " 1.52671030e-02 3.76521461e-02 1.20869847e-02 4.72583924e-04], shape=(40,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[1.4932165e-01 4.7701593e-02 6.4717375e-02 4.2232167e-02 1.1297029e-03\n",
      " 3.5490558e-02 1.8597409e-02 9.0150066e-02 1.4008065e-01 5.9023191e-04\n",
      " 2.9928902e-02 2.7531353e-01 2.9829118e-02 6.5976921e-03 9.2732388e-04\n",
      " 6.9158959e-01 2.7841747e-02 8.2588024e-02 5.9967833e-03 3.8921319e-02\n",
      " 2.2794393e-01 1.8347249e-03 8.9365282e+00 4.3531269e-02 2.9758116e-02\n",
      " 6.9974411e-01 3.2677306e-03 2.0806734e-02 7.3947644e-01 6.4790778e-02\n",
      " 3.1044846e-02 3.7712980e-02 5.2684136e-02 4.0629543e-02 1.3347105e-03\n",
      " 4.0520269e-02 1.7157784e-01 1.4010473e-01 1.1222886e-01 3.3925403e-02], shape=(40,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "crop_size = 48\n",
    "# use_channels = ['DAPI', 'CD45', 'PanCytoK', 'CD3e', 'CD4', 'CD8', 'PDGFRb', 'CD20', 'CD68', 'IgG', 'C1q']\n",
    "\n",
    "with h5py.File('/home/ingn/tmp/micron2-data/joined_dataset.hdf5', 'r') as f:\n",
    "    all_channels = [b.decode('UTF-8') for b in f['meta/channel_names'][:]]\n",
    "    print(all_channels)\n",
    "    \n",
    "    # just use all the channels\n",
    "    use_channels = all_channels\n",
    "\n",
    "    means = tf.constant([f[f'cell_intensity/{c}'].attrs['mean'] for c in use_channels], dtype=tf.float32)\n",
    "    stds =  tf.constant([f[f'cell_intensity/{c}'].attrs['std'] for c in use_channels], dtype=tf.float32)\n",
    "    print(means)\n",
    "    print(stds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '/home/ingn/tmp/micron2-data/moco-cells'\n",
    "if not os.path.isdir(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "with open(f'{outdir}/use_channels.txt', 'w+') as f:\n",
    "    for c in use_channels:\n",
    "        f.write(f'{c}\\n')\n",
    "        \n",
    "# import os\n",
    "# if os.path.exists(f'{outdir}/weights.h5'):\n",
    "#     model.load_weights(f'{outdir}/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1q', 'CD103', 'CD11c', 'CD134', 'CD138', 'CD20', 'CD31', 'CD3e', 'CD4', 'CD40', 'CD40LG', 'CD45', 'CD45RA', 'CD45RO', 'CD64', 'CD68', 'CD69', 'CD8', 'CD80', 'CD89', 'CXCL13', 'CXCR5', 'DAPI', 'FOXP3', 'GZMB', 'HLA-DR', 'IL7R', 'IgA', 'IgG', 'IgM', 'Ki-67', 'LAG3', 'OX40L', 'PD-1', 'PD-L1', 'PDGFRb', 'PNaD', 'PanCytoK', 'TIM3', 'aSMA']\n"
     ]
    }
   ],
   "source": [
    "print(use_channels)\n",
    "\n",
    "def process(x):\n",
    "    \"\"\"\n",
    "    x is [N, h, w, c]\n",
    "    \"\"\"\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = (x - means) / stds\n",
    "    \n",
    "#     x = tf.cast(x, tf.float32)/255.\n",
    "#     x = tf.transpose(tf.image.per_image_standardization(tf.transpose(x)))\n",
    "    return x\n",
    "    \n",
    "# Create a dataset with infinite repeating \n",
    "dataset = stream_dataset('/home/ingn/tmp/micron2-data/joined_dataset.hdf5', \n",
    "                         use_channels=use_channels,\n",
    "                         group_name='cells' )\n",
    "dataset = (dataset.repeat(None)\n",
    "           .shuffle(1024 * 5)\n",
    "           .map(process, num_parallel_calls=8)\n",
    "           .batch(32)\n",
    "           .prefetch(16)\n",
    "           #.apply(tf.data.experimental.prefetch_to_device(\"/gpu:0\"))\n",
    "          )\n",
    "\n",
    "# for sample_x in dataset:\n",
    "#     break\n",
    "    \n",
    "# print(sample_x.shape)\n",
    "# for k in range(sample_x.shape[-1]):\n",
    "#     print(use_channels[k], sample_x.numpy()[...,k].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_x = tf.image.random_crop(sample_x, size=(sample_x.shape[0], \n",
    "#                                                 crop_size, crop_size, \n",
    "#                                                 sample_x.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ingn/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 40 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "(1, 32)\n",
      "(1, 128)\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip (RandomFlip)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "random_rotation (RandomRotat multiple                  0         \n",
      "_________________________________________________________________\n",
      "random_translation (RandomTr multiple                  0         \n",
      "_________________________________________________________________\n",
      "random_crop (RandomCrop)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 2, 2, 2048)        23680832  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              multiple                  4194816   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  4128      \n",
      "=================================================================\n",
      "Total params: 29,011,040\n",
      "Trainable params: 28,965,600\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_x = tf.zeros([1, 64, 64, len(use_channels)],dtype=tf.float32)\n",
    "model = Encoder(input_shape=[crop_size, crop_size, len(use_channels)])\n",
    "y, z_g = model(sample_x, return_g=True)\n",
    "print(y.shape)\n",
    "print(z_g.shape)\n",
    "z = model.encode(sample_x)\n",
    "print(z.shape)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "(1, 32)\n",
      "(1, 128)\n",
      "Model: \"encoder_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip_1 (RandomFlip)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "random_rotation_1 (RandomRot multiple                  0         \n",
      "_________________________________________________________________\n",
      "random_translation_1 (Random multiple                  0         \n",
      "_________________________________________________________________\n",
      "random_crop_1 (RandomCrop)   multiple                  0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 2, 2, 2048)        23680832  \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  4194816   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  1049088   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  65664     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  4128      \n",
      "=================================================================\n",
      "Total params: 29,011,040\n",
      "Trainable params: 28,965,600\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # Placing the key encoder on CPU helps training speed, maybe\n",
    "with tf.device('/CPU:0'):\n",
    "# kmodel = Encoder(input_shape=sample_x.shape[1:])\n",
    "    kmodel = Encoder(input_shape=[crop_size, crop_size, len(use_channels)])\n",
    "    y, z_g = kmodel(sample_x, return_g=True)\n",
    "    print(y.shape)\n",
    "    print(z_g.shape)\n",
    "    z = kmodel.encode(sample_x)\n",
    "    print(z.shape)\n",
    "\n",
    "kmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the key queue\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8aaebc9781a47d88c18de603a57d8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    }
   ],
   "source": [
    "loss_history = train_moco(dataset, model, kmodel, \n",
    "                          lr=1e-4,\n",
    "                          max_queue_len=128, \n",
    "                          crop_size=crop_size,\n",
    "                          max_steps=2e5, temp=0.1,\n",
    "                          perturb=False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-d57f9e820f29>:4: RuntimeWarning: divide by zero encountered in log10\n",
      "  plt.plot(np.arange(lh), np.log10(loss_history), lw=0.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc0283ab370>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "lh = len(loss_history)\n",
    "plt.figure(figsize=(8,2))\n",
    "plt.plot(np.arange(lh), np.log10(loss_history), lw=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(f'{outdir}/weights.h5')\n",
    "np.save(f'{outdir}/loss_history.npy', np.array(loss_history),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process a whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: IOFromHDF5/HDF5IODataset/strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d25cfb1ccd1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m dataset = stream_dataset('/home/ingn/tmp/micron2-data/joined_dataset.hdf5', \n\u001b[0m\u001b[1;32m     15\u001b[0m                          \u001b[0muse_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                          \u001b[0mgroup_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tiles'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/micron2/micron2/data/load_nuclei.py\u001b[0m in \u001b[0;36mstream_dataset\u001b[0;34m(fpath, use_channels, group_name)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0mchannel_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtfio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIODataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'/{group_name}/{c}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muse_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   dataset = (tf.data.Dataset.zip(tuple(channel_ds))\n\u001b[1;32m     84\u001b[0m             .map(process_channels))\n",
      "\u001b[0;32m~/devel/micron2/micron2/data/load_nuclei.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0mchannel_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtfio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIODataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'/{group_name}/{c}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muse_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   dataset = (tf.data.Dataset.zip(tuple(channel_ds))\n\u001b[1;32m     84\u001b[0m             .map(process_channels))\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow_io/core/python/ops/io_dataset.py\u001b[0m in \u001b[0;36mfrom_hdf5\u001b[0;34m(cls, filename, dataset, spec, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IOFromHDF5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             return hdf5_dataset_ops.HDF5IODataset(\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow_io/core/python/ops/hdf5_dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, dataset, spec, internal)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HDF5IODataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             )\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1034\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m     return strided_slice(\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m   op = gen_array_ops.strided_slice(\n\u001b[0m\u001b[1;32m   1210\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10445\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10446\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10447\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10448\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10449\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2-tf/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 0 of dimension 0 out of bounds. [Op:StridedSlice] name: IOFromHDF5/HDF5IODataset/strided_slice/"
     ]
    }
   ],
   "source": [
    "# crop_frac = crop_size / 64\n",
    "# def process_crop(x):\n",
    "#     \"\"\"\n",
    "#     x is [N, h, w, c]\n",
    "#     \"\"\"\n",
    "#     x = tf.cast(x, tf.float32)\n",
    "#     x = (x - means) / stds\n",
    "    \n",
    "# #     x = tf.cast(x, tf.float32)/255.\n",
    "# #     x = tf.transpose(tf.image.per_image_standardization(tf.transpose(x)))\n",
    "#     x = tf.image.central_crop(x, crop_frac)\n",
    "#     return x\n",
    "\n",
    "# dataset = stream_dataset('/home/ingn/tmp/micron2-data/joined_dataset.hdf5', \n",
    "#                          use_channels=use_channels,\n",
    "#                          group_name='tiles'\n",
    "#                         )\n",
    "# dataset = (dataset.map(process_crop, num_parallel_calls=8)\n",
    "#            .batch(128)\n",
    "#            .prefetch(4)\n",
    "#           )\n",
    "\n",
    "# z = []\n",
    "# for batch in tqdm.tqdm(dataset):\n",
    "#     z.append(model.encode(batch, training=False).numpy())\n",
    "    \n",
    "# z = np.concatenate(z, axis=0)\n",
    "# print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f'{outdir}/z.npy', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
