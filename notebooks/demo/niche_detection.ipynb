{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from micron2.data import load_as_anndata\n",
    "from micron2.clustering import cluster_leiden, run_tsne, plot_embedding, cluster_leiden_cu\n",
    "from micron2.data import get_channel_means\n",
    "\n",
    "import scanpy as sc\n",
    "# import scrna\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"/storage/codex/datasets_v1/joined_dataset.h5ad\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.log1p(adata)\n",
    "clusters = cluster_leiden_cu(adata.X, resolution=0.8)\n",
    "print(clusters.shape)\n",
    "adata.obs['mean_leiden'] = clusters\n",
    "\n",
    "rcParams['figure.dpi'] = 180\n",
    "sc.pl.embedding(adata, basis='coordinates', color='mean_leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(scrna.plot_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_vars = [v for v in adata.var_names if v != 'DAPI']\n",
    "scrna.plot_heatmap(adata, hm_vars, groupby='mean_leiden', figsize=(4,6), z_score=1, drop_zeros=False,\n",
    "                   cmap='RdBu_r', center_cmap=0, x_font=6, y_font=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# form groups with a sliding window method\n",
    "\n",
    "![window](assets/fixed_window.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = adata.obsm['coordinates'].copy()\n",
    "print(coords.shape)\n",
    "\n",
    "# Flip the height coordinate\n",
    "coords[:,1] = -coords[:,1]\n",
    "\n",
    "# swap positions - coords[:,0] ~ width\n",
    "# but we want c1 to be height\n",
    "c1 = coords[:,1]\n",
    "c2 = coords[:,0]\n",
    "\n",
    "max_c1, max_c2 = np.max(c1), np.max(c2)\n",
    "print(max_c1, max_c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding window - squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square\n",
    "\n",
    "w = 100\n",
    "overlap = 0.1\n",
    "\n",
    "_, clusters = np.unique(clusters, return_inverse=True)\n",
    "u_clusters = np.unique(clusters)\n",
    "print(u_clusters)\n",
    "\n",
    "tot_cells = len(clusters)\n",
    "print(tot_cells)\n",
    "\n",
    "w2 = int(w // 2)\n",
    "print(w2)\n",
    "\n",
    "step_size = int(np.floor(w * (1-overlap)))\n",
    "print(step_size)\n",
    "\n",
    "cell_ids = np.array(adata.obs_names)\n",
    "\n",
    "centers_c1 = np.arange(w2, max_c1-w2, step_size, dtype=int)\n",
    "centers_c2 = np.arange(w2, max_c2-w2, step_size, dtype=int)\n",
    "\n",
    "cell_window_map = {}\n",
    "\n",
    "n_cells = np.zeros((len(centers_c1), len(centers_c2)))\n",
    "phenotypes_sums = np.zeros((len(centers_c1), len(centers_c2), len(u_clusters)))\n",
    "phenotypes_pcts = np.zeros((len(centers_c1), len(centers_c2), len(u_clusters)))\n",
    "window_id = np.zeros((len(centers_c1), len(centers_c2)), dtype=object)\n",
    "\n",
    "for i, c1_c in enumerate(centers_c1):\n",
    "    w_dim1 = [c1_c-w2, c1_c+w2]\n",
    "    w_cells_dim1 = (c1 > w_dim1[0]) & (c1 < w_dim1[1])\n",
    "    for j, c2_c in enumerate(centers_c2):\n",
    "        w_dim2 = [c2_c-w2, c2_c+w2]\n",
    "        w_cells_dim2 = (c2 > w_dim2[0]) & (c2 < w_dim2[1])\n",
    "        w_cells = w_cells_dim1 & w_cells_dim2\n",
    "        \n",
    "        w_n_cells = np.sum(w_cells)\n",
    "        n_cells[i,j] = w_n_cells\n",
    "\n",
    "                        \n",
    "        if w_n_cells == 0:\n",
    "            continue\n",
    "        else:\n",
    "            w_clusters = clusters[w_cells]\n",
    "            pfl_sum = np.zeros(len(u_clusters), dtype=np.float32)\n",
    "            pfl_pct = np.zeros(len(u_clusters), dtype=np.float32)\n",
    "            for u in u_clusters:\n",
    "                \n",
    "                pfl_sum[u] = (w_clusters == u).sum()\n",
    "                pfl_pct[u] = (w_clusters == u).sum() / w_n_cells\n",
    "        \n",
    "        phenotypes_sums[i,j,:] = pfl_sum\n",
    "        phenotypes_pcts[i,j,:] = pfl_pct\n",
    "        \n",
    "        w_id = f'window_{i}_{j}'\n",
    "        window_id[i,j] = w_id\n",
    "        cell_window_map[w_id] = cell_ids[w_cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# # sns.heatmap(phenotypes[:,:,3], square=True, cbar_kws=dict(shrink=0.1))\n",
    "# sns.heatmap(n_cells, square=True, cbar_kws=dict(shrink=0.1))\n",
    "# plt.gca().set_title('N cells')\n",
    "\n",
    "# plt.figure()\n",
    "# sns.heatmap(np.argmax(phenotypes, axis=-1), \n",
    "#             mask=n_cells==0,\n",
    "#             square=True, cbar_kws=dict(shrink=0.1), \n",
    "#             cmap='tab20c',)\n",
    "# plt.gca().set_title('Max cluster in region by %')\n",
    "\n",
    "phenotypes_flat = np.reshape(phenotypes_sums, (-1, phenotypes_sums.shape[-1]))\n",
    "print(phenotypes_flat.shape)\n",
    "\n",
    "# Cluster with leiden clustering or KMeans\n",
    "phenotypes_cluster_sums = cluster_leiden_cu(phenotypes_flat, resolution=0.6)\n",
    "phenotypes_cluster_sums_flat = phenotypes_cluster_sums.copy()\n",
    "# MBKM = MiniBatchKMeans(n_clusters=10, random_state=999)\n",
    "# phenotypes_cluster = MBKM.fit_predict(phenotypes_flat)\n",
    "\n",
    "_ , phenotypes_cluster_sums = np.unique(phenotypes_cluster_sums, return_inverse=True)\n",
    "phenotypes_cluster_sums = np.reshape(phenotypes_cluster_sums, phenotypes_sums.shape[:2])\n",
    "print(phenotypes_cluster_sums.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(phenotypes_cluster_sums, cmap='tab20')\n",
    "plt.colorbar()\n",
    "plt.gca().set_title('Regions clustered by phenotype profiles\\nSum of cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes_flat = np.reshape(phenotypes_pcts, (-1, phenotypes_pcts.shape[-1]))\n",
    "print(phenotypes_flat.shape)\n",
    "\n",
    "# Cluster with leiden clustering or KMeans\n",
    "phenotypes_cluster_pcts = cluster_leiden_cu(phenotypes_flat, resolution=0.6)\n",
    "phenotypes_cluster_pcts_flat = phenotypes_cluster_pcts.copy()\n",
    "# MBKM = MiniBatchKMeans(n_clusters=10, random_state=999)\n",
    "# phenotypes_cluster = MBKM.fit_predict(phenotypes_flat)\n",
    "\n",
    "_ , phenotypes_cluster_pcts = np.unique(phenotypes_cluster_pcts, return_inverse=True)\n",
    "phenotypes_cluster_pcts = np.reshape(phenotypes_cluster_pcts, phenotypes_pcts.shape[:2])\n",
    "print(phenotypes_cluster_pcts.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(phenotypes_cluster_pcts, cmap='tab20')\n",
    "plt.colorbar()\n",
    "plt.gca().set_title('Regions clustered by phenotype profiles\\nPercents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed k-Neighbors method\n",
    "\n",
    "- describe each cell by N=10 nearest neighbors\n",
    "- cluster cells by neighbor profiles, forcing k=10 clusters\n",
    "\n",
    "![neighbors](assets/10_neighbors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NearestNeighbors(n_neighbors=10, metric='minkowski', p=2).fit(coords)\n",
    "nbrs = nn_model.kneighbors(return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clusters = np.unique(clusters, return_inverse=True)\n",
    "u_clusters = np.unique(clusters)\n",
    "print(u_clusters)\n",
    "\n",
    "phenotypes = np.zeros((nbrs.shape[0], len(u_clusters)))\n",
    "print(phenotypes.shape)\n",
    "\n",
    "for i in tqdm.trange(nbrs.shape[0]):\n",
    "    v = clusters[list(nbrs[i]) + [i]]\n",
    "    p = np.zeros(len(u_clusters))\n",
    "    for ui, u in enumerate(u_clusters):\n",
    "        p[ui] = np.sum(v==u) / len(v)\n",
    "        \n",
    "    phenotypes[i, :] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MBKM = MiniBatchKMeans(n_clusters=10, random_state=999)\n",
    "phenotypes_cluster = MBKM.fit_predict(phenotypes)\n",
    "\n",
    "adata.obs['nolan_niches'] = pd.Categorical(phenotypes_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.dpi'] = 600\n",
    "sc.pl.embedding(adata, basis='coordinates', color='nolan_niches', s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding directly from images\n",
    "\n",
    "![dnn](assets/dnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_adata = load_as_anndata(\"/home/ingn/tmp/micron2-data/dataset_v2.hdf5\", \n",
    "                             obs_names='meta/Tile_IDs',\n",
    "                             featurekey='tile_intensity',\n",
    "                             coordkey='meta/tile_coordinates',\n",
    "                             flip_y=True,\n",
    "                             reverse_coords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.load('/home/ingn/tmp/micron2-data/single_moco_tiles_2/z.npy')\n",
    "groups = cluster_leiden_cu(z, resolution=0.6)\n",
    "tile_adata.obs['z_leiden'] = pd.Categorical(groups)\n",
    "print(z.shape, groups.shape, len(np.unique(groups)))\n",
    "\n",
    "rcParams['figure.dpi'] = 300\n",
    "sc.pl.embedding(tile_adata, basis='coordinates', color='z_leiden', s=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_bar(composition, axis=0, title=''):\n",
    "    \"\"\" \n",
    "    composition ~ N x M \n",
    "    axis - which axis to use as the \"categories\". \n",
    "           the other axis is used as the \"distribution\" within each \"category\"\n",
    "    \"\"\"\n",
    "    n_cats = composition.shape[axis] \n",
    "    dist_ax = 1 if axis==0 else 0\n",
    "    n_dists = composition.shape[dist_ax]\n",
    "    \n",
    "    vals = np.split(composition, n_dists, axis=dist_ax)\n",
    "    print(len(vals))\n",
    "    \n",
    "    plt.figure(figsize=(4,1), dpi=180)\n",
    "    ax = plt.gca()\n",
    "    bottoms = np.zeros(n_cats)\n",
    "    for ht in vals:\n",
    "        ht = np.squeeze(ht)\n",
    "        ax.bar(np.arange(n_cats), ht, bottom=bottoms)\n",
    "        bottoms += ht\n",
    "    ax.set_xticks(np.arange(n_cats))\n",
    "    ax.set_xticklabels(ax.get_xticks(), fontsize=6)\n",
    "    ax.set_ylabel('Percent')\n",
    "    ax.set_xlabel('Niche ID')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "stacked_bar(niche_composition, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window -- percents\n",
    "\n",
    "n_clusters = len(np.unique(adata.obs.mean_leiden))\n",
    "\n",
    "niche_composition = []\n",
    "\n",
    "for c in np.unique(phenotypes_cluster_pcts):\n",
    "    winds = window_id[phenotypes_cluster_pcts==c].ravel()\n",
    "    counts = np.zeros(n_clusters)\n",
    "    n_cells = 0\n",
    "    for wi in winds:\n",
    "        if wi==0: continue\n",
    "        cells = cell_window_map[wi]\n",
    "        cell_clusters = np.array(adata.obs.loc[cells, 'mean_leiden'].values)\n",
    "        for cc in cell_clusters:\n",
    "            counts[int(cc)] += 1\n",
    "            n_cells += 1\n",
    "    counts = counts / sum(counts)\n",
    "    niche_composition.append(counts)\n",
    "    \n",
    "print(len(niche_composition))\n",
    "niche_composition = np.array(niche_composition)\n",
    "print(niche_composition.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(phenotypes_cluster_pcts, cmap='tab20')\n",
    "plt.colorbar()\n",
    "plt.gca().set_title('Regions clustered by phenotype profiles\\nPercent of cells')\n",
    "\n",
    "stacked_bar(niche_composition, axis=0, title='Sliding window -- percent')\n",
    "\n",
    "cm = sns.clustermap(niche_composition, figsize=(8,4), cmap='bone_r', square=True,\n",
    "                    col_cluster=False,\n",
    "               xticklabels=True, yticklabels=True, metric='euclidean', \n",
    "               method='ward')\n",
    "\n",
    "cm.ax_heatmap.set_title('Sliding window -- percent')\n",
    "\n",
    "cm=sns.clustermap(pd.DataFrame(niche_composition).corr(), \n",
    "                  cmap='RdBu_r', center=0,\n",
    "               figsize=(3,3), xticklabels=True, yticklabels=True)\n",
    "_ = cm.ax_heatmap.set_xticklabels(cm.ax_heatmap.get_xticklabels(), fontsize=4)\n",
    "_ = cm.ax_heatmap.set_yticklabels(cm.ax_heatmap.get_yticklabels(), fontsize=4)\n",
    "cm.ax_heatmap.set_title('Sliding window -- percent', fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window -- sums\n",
    "n_clusters = len(np.unique(adata.obs.mean_leiden))\n",
    "print(n_clusters)\n",
    "\n",
    "niche_composition = []\n",
    "\n",
    "for c in np.unique(phenotypes_cluster_sums):\n",
    "    winds = window_id[phenotypes_cluster_sums==c].ravel()\n",
    "    counts = np.zeros(n_clusters)\n",
    "    for wi in winds:\n",
    "        if wi==0: continue\n",
    "        cells = cell_window_map[wi]\n",
    "        cell_clusters = adata.obs.loc[cells, 'mean_leiden'].values\n",
    "        for cc in cell_clusters:\n",
    "            counts[int(cc)] += 1\n",
    "    counts = counts / sum(counts)\n",
    "    niche_composition.append(counts)\n",
    "    \n",
    "niche_composition = np.array(niche_composition)\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(phenotypes_cluster_sums, cmap='tab20')\n",
    "plt.colorbar()\n",
    "plt.gca().set_title('Regions clustered by phenotype profiles\\nSum of cells')\n",
    "\n",
    "stacked_bar(niche_composition, axis=0, title='Sliding window -- sum')\n",
    "\n",
    "cm = sns.clustermap(niche_composition, figsize=(8,4), cmap='bone_r', square=True,\n",
    "                    col_cluster=False,\n",
    "               xticklabels=True, yticklabels=True, metric='euclidean', \n",
    "               method='ward')\n",
    "\n",
    "cm.ax_heatmap.set_title('Sliding window -- sum')\n",
    "\n",
    "cm=sns.clustermap(pd.DataFrame(niche_composition).corr(), \n",
    "                  cmap='RdBu_r', center=0,\n",
    "               figsize=(3,3), xticklabels=True, yticklabels=True)\n",
    "_ = cm.ax_heatmap.set_xticklabels(cm.ax_heatmap.get_xticklabels(), fontsize=4)\n",
    "_ = cm.ax_heatmap.set_yticklabels(cm.ax_heatmap.get_yticklabels(), fontsize=4)\n",
    "cm.ax_heatmap.set_title('Sliding window -- sum', fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-Neighbors niches\n",
    "n_clusters = len(np.unique(adata.obs.mean_leiden))\n",
    "print(n_clusters)\n",
    "\n",
    "niche_composition = []\n",
    "\n",
    "for c in np.unique(adata.obs.nolan_niches):\n",
    "    cl = adata.obs.mean_leiden[adata.obs.nolan_niches==c]\n",
    "    counts = np.zeros(n_clusters)\n",
    "    for c in np.unique(cl):\n",
    "        counts[int(c)] = (cl == c).sum()\n",
    "    \n",
    "    counts = counts / sum(counts)\n",
    "    niche_composition.append(counts)\n",
    "    \n",
    "    \n",
    "niche_composition = np.array(niche_composition)\n",
    "\n",
    "sc.pl.embedding(adata, basis='coordinates', color='nolan_niches', s=1)\n",
    "\n",
    "stacked_bar(niche_composition, axis=0, title='Cell-wise -- fixed k-Neighbors')\n",
    "\n",
    "cm = sns.clustermap(niche_composition, figsize=(8,4), cmap='bone_r', square=True,\n",
    "                    col_cluster=False,\n",
    "               xticklabels=True, yticklabels=True, metric='euclidean', \n",
    "               method='ward')\n",
    "\n",
    "cm.ax_heatmap.set_title('Cell-wise -- fixed k-Neighbors')\n",
    "\n",
    "cm=sns.clustermap(pd.DataFrame(niche_composition).corr(), \n",
    "                  cmap='RdBu_r', center=0,\n",
    "               figsize=(3,3), xticklabels=True, yticklabels=True)\n",
    "_ = cm.ax_heatmap.set_xticklabels(cm.ax_heatmap.get_xticklabels(), fontsize=4)\n",
    "_ = cm.ax_heatmap.set_yticklabels(cm.ax_heatmap.get_yticklabels(), fontsize=4)\n",
    "cm.ax_heatmap.set_title('Cell-wise -- fixed k-Neighbors', fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MoCo clustering\n",
    "n_clusters = len(np.unique(adata.obs.mean_leiden))\n",
    "\n",
    "niche_composition = []\n",
    "for c in np.unique(tile_adata.obs.z_leiden):\n",
    "    tids = tile_adata.obs_names[tile_adata.obs.z_leiden==c]\n",
    "    counts = np.zeros(n_clusters)\n",
    "    for t in tids:\n",
    "        cells = tile_adata.uns['tile_nuclei'][t]\n",
    "        cell_clusters = adata.obs.loc[cells, 'mean_leiden'].values\n",
    "        for cc in cell_clusters:\n",
    "            counts[int(cc)] += 1\n",
    "    counts = counts / sum(counts) \n",
    "    niche_composition.append(counts)\n",
    "    \n",
    "niche_composition = np.array(niche_composition)\n",
    "\n",
    "sc.pl.embedding(tile_adata, basis='coordinates', color='z_leiden', s=25)\n",
    "\n",
    "stacked_bar(niche_composition, axis=0, title='Sliding window -- Unsupervised')\n",
    "\n",
    "cm = sns.clustermap(niche_composition, figsize=(8,4), cmap='bone_r', square=True,\n",
    "                    col_cluster=False,\n",
    "               xticklabels=True, yticklabels=True, metric='euclidean', \n",
    "               method='ward')\n",
    "cm.ax_heatmap.set_title('Sliding window -- Unsupervised')\n",
    "\n",
    "cm=sns.clustermap(pd.DataFrame(niche_composition).corr(), \n",
    "                  cmap='RdBu_r', center=0,\n",
    "               figsize=(3,3), xticklabels=True, yticklabels=True)\n",
    "_ = cm.ax_heatmap.set_xticklabels(cm.ax_heatmap.get_xticklabels(), fontsize=4)\n",
    "_ = cm.ax_heatmap.set_yticklabels(cm.ax_heatmap.get_yticklabels(), fontsize=4)\n",
    "cm.ax_heatmap.set_title('Sliding window -- Unsupervised', fontsize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
