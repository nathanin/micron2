{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from micron2.clustering import Encoder, Classifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this cell to load from multiple samples, and concatenate. \n",
    "# make sure to place channels correctly, in case they're permuted for some reason between collections.\n",
    "import glob\n",
    "srch = '/storage/codex/preprocessed_data/pembro_TLS_panel/210702_PembroRT_Cas19_TLSpanel_reg2/collection*'\n",
    "\n",
    "image_files = sorted(glob.glob(f'{srch}/training_cells_images.npy'))\n",
    "annot_files = sorted(glob.glob(f'{srch}/training_cells_annots.npy'))\n",
    "channel_files = sorted(glob.glob(f'{srch}/training_cells_channels.npy'))\n",
    "\n",
    "image_files\n",
    "\n",
    "images = np.load(image_files[0])\n",
    "annots = np.load(annot_files[0])\n",
    "channels = np.load(channel_files[0])\n",
    "\n",
    "channels = {k:i for i,k in enumerate(channels)}\n",
    "\n",
    "print(images.shape, images.dtype)\n",
    "print(annots.shape)\n",
    "print(np.unique(annots, return_counts=True))\n",
    "print(channels)\n",
    "\n",
    "perm = np.random.choice(images.shape[0], images.shape[0], replace=False)\n",
    "images = images[perm]\n",
    "annots = annots[perm]\n",
    "\n",
    "u_annots, annots_int = np.unique(annots, return_inverse=True)\n",
    "labels = np.eye(len(u_annots))[annots_int]\n",
    "# labels[annots == '', :] = 0 \n",
    "labels = labels[:,1:]\n",
    "\n",
    "print(labels.shape)\n",
    "print('labelled cells:', np.sum(np.sum(labels, axis=1)>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '/home/ingn/devel/micron2/notebooks/devel_debug/moco-models/weights_cls.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = [52, 52, len(channels)]\n",
    "print(data_shape)\n",
    "\n",
    "x_dummy = tf.zeros([1] + data_shape, dtype=tf.float32)\n",
    "print(x_dummy.shape)\n",
    "\n",
    "encoder = Encoder(data_shape=data_shape, z_dim=256, encoder_type='EfficientNetB1')\n",
    "z = encoder(x_dummy)\n",
    "\n",
    "classifier = Classifier(encoder=encoder, n_classes=labels.shape[1], mlp_dim=128) \n",
    "y = classifier(x_dummy)\n",
    "\n",
    "print(z.shape)\n",
    "print(y.shape)\n",
    "\n",
    "classifier.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    \"\"\"\n",
    "    x is [N, h, w, c]\n",
    "    \"\"\"\n",
    "    x = tf.cast(x, tf.float32)/255.\n",
    "    x = tf.image.central_crop(x, 0.8125)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "# Create a dataset with infinite repeating \n",
    "batch_size = 32\n",
    "dataset = (tf.data.Dataset.from_tensor_slices(images)\n",
    "           .map(process, num_parallel_calls=4)\n",
    "           .batch(batch_size, drop_remainder=False)\n",
    "           .prefetch(1)\n",
    "          )\n",
    "\n",
    "for batch in dataset:\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.auto as tqdm\n",
    "\n",
    "preds = []\n",
    "for b in tqdm.tqdm(dataset):\n",
    "    y = classifier(b, training=False)\n",
    "    preds.append(y.numpy().copy())\n",
    "    \n",
    "preds = np.concatenate(preds, axis=0)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {v:i-1 for i,v in enumerate(u_annots) if i>0}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_labels = labels.sum(axis=1) > 0\n",
    "np.mean(y[has_labels] == np.argmax(labels, axis=1)[has_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.argmax(labels, axis=1)[has_labels], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "chs = list(channels.keys())\n",
    "\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "# inds = np.random.choice(images.shape[0], 4, replace=False)\n",
    "\n",
    "u_cts = np.unique(annots)\n",
    "\n",
    "m = 1\n",
    "for i,ct in enumerate(label_map.keys()):\n",
    "    inds = np.nonzero(y==label_map[ct])[0] \n",
    "    if len(inds)==0:\n",
    "        continue\n",
    "    ind = np.random.choice(inds)\n",
    "    \n",
    "    for j,ch in enumerate(chs):\n",
    "        ax = fig.add_subplot(len(u_cts),len(chs),m)\n",
    "        m += 1\n",
    "        \n",
    "        k = channels[ch]\n",
    "        img = images[ind, :, :, k] / 255.\n",
    "        \n",
    "        b = ax.matshow(img, vmin=0, vmax=1)\n",
    "        # plt.colorbar(b, ax=ax)\n",
    "        ax.axis('off')\n",
    "    \n",
    "        if i==0:\n",
    "            ax.set_title(ch)\n",
    "        \n",
    "        if j==0:\n",
    "            ax.annotate(ct, (0.05, 0.8), xycoords='axes fraction', color='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-relief",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-crest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (micron2-tf)",
   "language": "python",
   "name": "micron2-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
