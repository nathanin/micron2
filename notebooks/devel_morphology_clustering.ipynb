{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'micron2.codexutils.pull_nuclei'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c26b5adc98d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmicron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodexutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstream_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/micron2/micron2/codexutils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpull_nuclei\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpull_nuclei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload_nuclei\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'micron2.codexutils.pull_nuclei'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from micron2.data import stream_dataset\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "from tensorflow.keras.layers import (Dense, Conv2D, Dropout, BatchNormalization, Conv2DTranspose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('/dev/shm/dataset.hdf5', 'r')\n",
    "print(f['meta/channel_names'][:])\n",
    "use_channels = [b.decode('UTF-8') for b in f['meta/channel_names'][:]]\n",
    "# fn = lambda x,y: print(x)\n",
    "print(f.keys())\n",
    "print(f['cells'].keys())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64, 64, 3)\n",
      "1796.6393\n",
      "420.52942\n",
      "86.435295\n"
     ]
    }
   ],
   "source": [
    "# x = load_dataset('tests/dataset.hdf5', use_channels=['DAPI', 'CD45', 'PanCytoK', 'CD31', 'PDGFRb', 'aSMA', 'Ki-67'],\n",
    "#                  verbose=True)\n",
    "# print(x.shape)\n",
    "\n",
    "print(use_channels)\n",
    "def process(x):\n",
    "    x = tf.cast(x, tf.float32)/255.\n",
    "    return x\n",
    "    \n",
    "dataset = stream_dataset('/dev/shm/dataset.hdf5', use_channels=use_channels)\n",
    "dataset = (dataset.repeat(10)\n",
    "           .shuffle(1024 * 6)\n",
    "           .map(process)\n",
    "           .batch(16)\n",
    "           .prefetch(8)\n",
    "           #.apply(tf.data.experimental.prefetch_to_device(\"/gpu:0\"))\n",
    "          )\n",
    "\n",
    "for sample_x in dataset:\n",
    "    break\n",
    "    \n",
    "print(sample_x.shape)\n",
    "for k in range(sample_x.shape[-1]):\n",
    "    print(sample_x.numpy()[...,k].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 48, 48, 3)\n",
      "(16, 256)\n",
      "(16, 32)\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_shape=[64, 64, 3]):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.n_channels = input_shape[-1]\n",
    "        self.n_upsamples = 7\n",
    "        self.conv_1 = tf.keras.applications.ResNet50V2(include_top=False, weights=None,\n",
    "                                                       input_shape=input_shape,\n",
    "                                                       pooling='average')\n",
    "        self.conv_2 = Conv2D(filters=256, kernel_size=(2,2), strides=(1,1), \n",
    "                             padding='same', activation='relu')\n",
    "        \n",
    "        self.g_fn = Dense(32, activation=None, name='g_simclr')\n",
    "        \n",
    "        self.build_upsample(name='up_large')\n",
    "        self.build_upsample(name='up_small')\n",
    "        \n",
    "    def build_upsample(self, name='upsample'):\n",
    "        p_act = dict(padding='same', activation='relu')\n",
    "        setattr(self, f'{name}_0', Conv2DTranspose(filters=256,  kernel_size=(2,2),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_1', Conv2DTranspose(filters=128,  kernel_size=(3,3),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_2', Conv2DTranspose(filters=64,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_3', Conv2DTranspose(filters=64,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_4', Conv2DTranspose(filters=64,  kernel_size=(3,3),\n",
    "                                        strides=(1,1), **p_act))\n",
    "        setattr(self, f'{name}_5', Conv2DTranspose(filters=self.n_channels,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_6', Conv2DTranspose(filters=self.n_channels,  kernel_size=(3,3),\n",
    "                                        strides=(1,1), **p_act))\n",
    "        \n",
    "    def apply_upsample(self, z, name='upsample'):\n",
    "        for j in range(self.n_upsamples):\n",
    "            z = getattr(self, f'{name}_{j}')(z)\n",
    "        return z\n",
    "        \n",
    "    def call(self, x, return_g=False):\n",
    "        x1 = self.conv_1(x)\n",
    "        x2 = self.conv_2(x1)\n",
    "        \n",
    "        # Two parallel upsampling paths\n",
    "        x1u = self.apply_upsample(x1, name='up_large')\n",
    "        x2u = self.apply_upsample(x2, name='up_small')\n",
    "\n",
    "        xout = tf.reduce_mean([x1u, x2u], axis=0)\n",
    "        xout = tf.image.resize_with_crop_or_pad(xout, x.shape[1], x.shape[2])\n",
    "        if return_g:\n",
    "            g = self.g_fn(tf.reduce_mean(x2, axis=[1,2]))\n",
    "            return xout, g\n",
    "        return xout  \n",
    "    \n",
    "    def encode_g(self, x):\n",
    "        # Apply g function for simclr\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = tf.reduce_mean(x, axis=[1,2])\n",
    "        x = self.g_fn(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x, retval=1):\n",
    "        if retval == 0:\n",
    "            x = self.conv_1(x)\n",
    "        elif retval == 1:\n",
    "            x = self.conv_1(x)\n",
    "            x = self.conv_2(x)\n",
    "            \n",
    "        return tf.reduce_mean(x, axis=[1,2])\n",
    "        \n",
    "sample_x = tf.image.random_crop(sample_x, size=(sample_x.shape[0], 48, 48, sample_x.shape[-1]))\n",
    "ae_model = Autoencoder(input_shape=sample_x.shape[1:])\n",
    "y = ae_model(sample_x)\n",
    "print(y.shape)\n",
    "z = ae_model.encode(sample_x)\n",
    "print(z.shape)\n",
    "z_g = ae_model.encode_g(sample_x)\n",
    "print(z_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Functional)      (None, 2, 2, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              multiple                  2097408   \n",
      "_________________________________________________________________\n",
      "g_simclr (Dense)             multiple                  8224      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  2097408   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr multiple                  295040    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr multiple                  204864    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr multiple                  102464    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr multiple                  36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr multiple                  4803      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr multiple                  84        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr multiple                  262400    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr multiple                  295040    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr multiple                  204864    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT multiple                  102464    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT multiple                  36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT multiple                  4803      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT multiple                  84        \n",
      "=================================================================\n",
      "Total params: 29,318,606\n",
      "Trainable params: 29,273,166\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aacffeb173bf4e5dba2f6e3cd900c170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-95965c59e289>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-95965c59e289>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mxout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d669e6c0d04e>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m--> 385\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    574\u001b[0m       \u001b[0;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m     output, mean, variance = tf_utils.smart_cond(training, train_op,\n\u001b[0m\u001b[1;32m    577\u001b[0m                                                  _fused_batch_norm_inference)\n\u001b[1;32m    578\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_add_or_remove_bessels_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     62\u001b[0m     return control_flow_ops.cond(\n\u001b[1;32m     63\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m---> 64\u001b[0;31m   return smart_module.smart_cond(\n\u001b[0m\u001b[1;32m     65\u001b[0m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm_inference\u001b[0;34m()\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fused_batch_norm_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       return nn.fused_batch_norm(\n\u001b[0m\u001b[1;32m    559\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m           \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[1;32m   1635\u001b[0m   \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_epsilon\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmin_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m   y, running_mean, running_var, _, _, _ = gen_nn_ops.fused_batch_norm_v3(\n\u001b[0m\u001b[1;32m   1638\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m       \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_v3\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4259\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4260\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4261\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FusedBatchNormV3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4262\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epsilon\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Normal training -- autoencoder only\n",
    "def train_loop(dataset, model):\n",
    "    mse_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "\n",
    "    pbar = tqdm.tqdm(enumerate(dataset))\n",
    "\n",
    "    losses = []\n",
    "    for i, batch in pbar:\n",
    "        with tf.GradientTape() as tape:\n",
    "            xout = model(batch)\n",
    "            loss = mse_fn(batch, xout)\n",
    "        losses.append(loss.numpy())\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optim.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            pbar.set_description(f'mean loss = {np.mean(losses):3.5e}')\n",
    "            losses = []\n",
    "            \n",
    "train_loop(dataset, ae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf2c64db6cb48888c31816d7f7689aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-133078bb9edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain_loop_grad_accum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-133078bb9edf>\u001b[0m in \u001b[0;36mtrain_loop_grad_accum\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mstash_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1065\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1068\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_FusedBatchNormV3Grad\u001b[0;34m(op, *grad)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FusedBatchNormV3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FusedBatchNormV3Grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_BaseFusedBatchNormGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_BaseFusedBatchNormGrad\u001b[0;34m(op, version, *grad)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reserve_space_3\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m     \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"NCHW\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m       \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_grad_v3\u001b[0;34m(y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4005\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4006\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4007\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4008\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FusedBatchNormGradV3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4009\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserve_space_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Autoencoder only but with gradient accumulation\n",
    "def train_loop_grad_accum(dataset, model):\n",
    "    mse_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    pbar = tqdm.tqdm(enumerate(dataset))\n",
    "    losses = []\n",
    "    grad_dict = {v.name: [] for v in model.trainable_variables}\n",
    "    \n",
    "    def stash_grads(grads, grad_dict, trainable_variables):\n",
    "        for i, v in enumerate(trainable_variables):\n",
    "            grad_dict[v.name].append(grads[i])\n",
    "    \n",
    "    def mean_grads(grad_dict, trainable_variables):\n",
    "        grads = [tf.reduce_mean(grad_dict[v.name], axis=0) for v in trainable_variables]\n",
    "        return grads\n",
    "    \n",
    "    for i, batch in pbar:\n",
    "        with tf.GradientTape() as tape:\n",
    "            xout = model(batch)\n",
    "            loss = mse_fn(batch, xout)\n",
    "        losses.append(loss.numpy())\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        \n",
    "        stash_grads(grads, grad_dict, model.trainable_variables)\n",
    "        if i % 32 == 0:\n",
    "            grads = mean_grads(grad_dict, model.trainable_variables)\n",
    "            optim.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            grad_dict = {v.name: [] for v in model.trainable_variables}\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            pbar.set_description(f'mean loss = {np.mean(losses):3.5e}')\n",
    "            losses = []\n",
    "            \n",
    "train_loop_grad_accum(dataset, ae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ffef3abd764dd69cfaae91d560f60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def similarity(u, tau=1.0):\n",
    "    nu = tf.norm(u, ord=2, keepdims=True, axis=-1)\n",
    "    sim = tf.tensordot(u, tf.transpose(u), 1) \n",
    "    return sim / (tf.constant(1e-9) + (tau * nu * tf.transpose(nu)))\n",
    "\n",
    "\n",
    "def simclr_loss_fn(z_i, tau=1.):\n",
    "    \"\"\"\n",
    "    A Simple Framework for Contrastive learning of Visual Representations\n",
    "    Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, 2020.  \n",
    "    https://arxiv.org/abs/2002.05709\n",
    "    \"\"\"\n",
    "\n",
    "    s = tf.exp(similarity(z_i, tau=tau))\n",
    "    i_part, j_part = tf.split(s, 2, 0)\n",
    "\n",
    "    total_i = tf.reduce_sum(i_part, axis=-1) - tf.linalg.diag_part(i_part)\n",
    "    total_j = tf.reduce_sum(j_part, axis=-1) - tf.linalg.diag_part(j_part)\n",
    "\n",
    "    l_i = -tf.math.log( tf.linalg.diag_part(i_part) / total_i )\n",
    "    l_j = -tf.math.log( tf.linalg.diag_part(j_part) / total_j )\n",
    "\n",
    "    loss = tf.reduce_sum(l_i + l_j)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def perturb_x(x):\n",
    "    x = tf.image.random_crop(x, size=(x.shape[0], 48, 48, x.shape[-1]))\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "# Autoencoder + simCLR. Use gradient accumulation for simCLR loss. \n",
    "# Autoencoder is trained every step\n",
    "def train_AE_simCLR(dataset, model):\n",
    "    mse_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    simclr_optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    pbar = tqdm.tqdm(enumerate(dataset))\n",
    "    losses, sc_losses = [], []\n",
    "    prev_loss, prev_sc_loss = 0, 0\n",
    "    \n",
    "    def stash_grads(grads, grad_dict, trainable_variables):\n",
    "        for i, v in enumerate(trainable_variables):\n",
    "            if grads[i] is None:\n",
    "                grad_dict[v.name].append(tf.zeros(v.shape, dtype=tf.float32))\n",
    "            else:\n",
    "                grad_dict[v.name].append(grads[i])\n",
    "    \n",
    "    def mean_grads(grad_dict, trainable_variables):\n",
    "        grads = [tf.reduce_mean(grad_dict[v.name], axis=0) for v in trainable_variables]\n",
    "        return grads\n",
    "    \n",
    "    # Grab variables for the AE portion because otherwise theres tons of warnings\n",
    "    ae_vars = [v for v in ae_model.trainable_variables if 'g_simclr' not in v.name]\n",
    "    \n",
    "    grad_dict = {v.name: [] for v in model.trainable_variables}\n",
    "    for i, batch in pbar:\n",
    "        batch_in = tf.image.random_crop(batch, size=(batch.shape[0], 48, 48, batch.shape[-1]))\n",
    "        batch_p = perturb_x(batch)\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            xout1, g1 = model(batch_in, return_g=True)\n",
    "            xout2, g2 = model(batch_p, return_g=True)\n",
    "            \n",
    "            mse_loss = mse_fn(tf.concat([batch_in, batch_p], axis=0), \n",
    "                              tf.concat([xout1, xout2], axis=0))\n",
    "            l_simclr = simclr_loss_fn(tf.concat([g1, g2], axis=0), tau=0.1)\n",
    "            \n",
    "        losses.append(mse_loss.numpy())\n",
    "        sc_losses.append(l_simclr.numpy())\n",
    "        mse_grads = tape.gradient(mse_loss, ae_vars)\n",
    "        simclr_grads = tape.gradient(l_simclr, model.trainable_variables)\n",
    "        del tape\n",
    "        \n",
    "        optim.apply_gradients(zip(mse_grads, ae_vars))\n",
    "        stash_grads(simclr_grads, grad_dict, model.trainable_variables)\n",
    "        if i % 16 == 0:\n",
    "            simclr_grads = mean_grads(grad_dict, model.trainable_variables)\n",
    "            simclr_optim.apply_gradients(zip(simclr_grads, model.trainable_variables))\n",
    "            grad_dict = {v.name: [] for v in model.trainable_variables}\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            m_loss = np.mean(losses)\n",
    "            m_sc_losses = np.mean(sc_losses)\n",
    "            #pbar.set_description(f'mse_loss = {np.mean(losses):3.5e} simclr_loss = {np.mean(sc_losses):3.5e}')\n",
    "            pbar.set_description(f'd(mse_loss) = {prev_loss-m_loss:3.5e}\\td(simclr_loss) = {prev_sc_loss-m_sc_losses:3.5e}')\n",
    "            prev_loss = np.mean([prev_loss, m_loss])\n",
    "            prev_sc_loss = np.mean([prev_sc_loss, m_sc_losses])\n",
    "            losses, sc_losses = [], []\n",
    "            \n",
    "train_AE_simCLR(dataset, ae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c508ac225369409b8a42821e8102d438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(146791, 256)\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "def process(x):\n",
    "    # x = tf.image.random_crop(x, size=(x.shape[0], 48, 48, x.shape[-1]))\n",
    "    x = tf.cast(x, tf.float32)/255.\n",
    "    return x\n",
    "    \n",
    "# use_channels=['DAPI', 'CD45', 'PanCytoK']\n",
    "# use_channels=['DAPI', 'CD45', 'PanCytoK', 'CD31', 'PDGFRb', 'aSMA', 'Ki-67']\n",
    "dataset = stream_dataset('tests/dataset.hdf5', use_channels = use_channels)\n",
    "dataset = (dataset.map(process)\n",
    "           .batch(64)\n",
    "          )\n",
    "\n",
    "z = []\n",
    "for batch in tqdm.tqdm(dataset):\n",
    "    z.append(ae_model.encode_g(batch).numpy().copy())\n",
    "    \n",
    "z = np.concatenate(z, axis=0)\n",
    "print(z.shape)\n",
    "print((z.sum(0)==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'simclr_model'\n",
    "np.save(f'{outdir}/z.npy', z)\n",
    "ae_model.save_weights(f\"{outdir}/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel 0\tpred 1013.63\treal 1028.78\n",
      "channel 1\tpred 290.24\treal 257.13\n",
      "channel 2\tpred 0.00\treal 43.75\n",
      "5 0\n",
      "0 63.411766 62.488564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faf5d7d5280>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "sample_xout = ae_model(sample_x)\n",
    "for j in range(sample_x.shape[-1]):\n",
    "    print(f'channel {j}\\t' +\\\n",
    "          f'pred {tf.reduce_sum(sample_xout[...,j]).numpy():<4.2f}\\t' +\\\n",
    "          f'real {tf.reduce_sum(sample_x[...,j]).numpy():<4.2f}')\n",
    "\n",
    "idx = np.random.choice(sample_xout.shape[0])\n",
    "jdx = np.random.choice(sample_xout.shape[-1])\n",
    "\n",
    "jdx = 0\n",
    "\n",
    "print(idx, jdx)\n",
    "sx = sample_x.numpy()[idx, :,:, jdx]\n",
    "sxout = sample_xout.numpy()[idx, :,:, jdx] \n",
    "print(jdx, sx.sum(), sxout.sum())\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(sx)# / sx.max())\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(sxout)# / sxout.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
