{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from micron2.codexutils import stream_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Dense, Conv2D, Dropout, BatchNormalization, Conv2DTranspose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.hdf5  test_codexutils__pull_nuclei.ipynb  test_imports.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'DAPI' b'OX40L' b'CD45' b'CD20' b'CD134' b'CD68' b'CD31' b'CD103'\n",
      " b'HLA-DR' b'CXCR5' b'IgG' b'CD3e' b'Ki-67' b'LAG3' b'CXCL13' b'IgA'\n",
      " b'CD89' b'PNaD' b'PD-L1' b'PD-1' b'CD11c' b'CD80' b'CD69' b'TIM3'\n",
      " b'CD45RO' b'CD40LG' b'FOXP3' b'CD64' b'GZMB' b'C1q' b'CD40' b'CD45RA'\n",
      " b'CD138' b'IL7R' b'IgM' b'PDGFRb' b'aSMA' b'CD8' b'CD4' b'PanCytoK']\n",
      "<KeysViewHDF5 ['cells', 'meta']>\n",
      "<KeysViewHDF5 ['C1q', 'CD103', 'CD11c', 'CD134', 'CD138', 'CD20', 'CD31', 'CD3e', 'CD4', 'CD40', 'CD40LG', 'CD45', 'CD45RA', 'CD45RO', 'CD64', 'CD68', 'CD69', 'CD8', 'CD80', 'CD89', 'CXCL13', 'CXCR5', 'DAPI', 'FOXP3', 'GZMB', 'HLA-DR', 'IL7R', 'IgA', 'IgG', 'IgM', 'Ki-67', 'LAG3', 'OX40L', 'PD-1', 'PD-L1', 'PDGFRb', 'PNaD', 'PanCytoK', 'TIM3', 'aSMA']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File('tests/dataset.hdf5', 'r')\n",
    "print(f['meta/channel_names'][:])\n",
    "# fn = lambda x,y: print(x)\n",
    "print(f.keys())\n",
    "print(f['cells'].keys())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = load_dataset('tests/dataset.hdf5', use_channels=['DAPI', 'CD45', 'PanCytoK', 'CD31', 'PDGFRb', 'aSMA', 'Ki-67'],\n",
    "#                  verbose=True)\n",
    "# print(x.shape)\n",
    "\n",
    "def process(x):\n",
    "    x = tf.cast(x, tf.float32)/255.\n",
    "    return x\n",
    "    \n",
    "dataset = stream_dataset('tests/dataset.hdf5', use_channels=['DAPI', 'CD45', 'PanCytoK', 'CD31', 'PDGFRb', 'aSMA', 'Ki-67'],)\n",
    "dataset = (dataset.repeat(10)\n",
    "           .shuffle(4096)\n",
    "           .map(process)\n",
    "           .batch(32)\n",
    "          )\n",
    "\n",
    "for x in dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ing/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 7)\n",
      "(32, 2048)\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_shape=[64, 64, 3]):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.n_channels = input_shape[-1]\n",
    "        self.conv_1 = tf.keras.applications.ResNet50V2(include_top=False, weights=None,\n",
    "                                                       input_shape=input_shape,\n",
    "                                                       pooling='average')\n",
    "        self.deconv_1 = Conv2DTranspose(filters=256,  kernel_size=(2,2),\n",
    "                                        strides=(2,2), padding='same')\n",
    "        self.deconv_1_1 = Conv2DTranspose(filters=256,  kernel_size=(2,2),\n",
    "                                        strides=(1,1), padding='same')\n",
    "        self.deconv_2 = Conv2DTranspose(filters=128,  kernel_size=(4,4),\n",
    "                                        strides=(2,2), padding='same')\n",
    "        self.deconv_2_1 = Conv2DTranspose(filters=128,  kernel_size=(4,4),\n",
    "                                        strides=(1,1), padding='same')\n",
    "        self.deconv_3 = Conv2DTranspose(filters=64,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), padding='same')\n",
    "        self.deconv_3_1 = Conv2DTranspose(filters=64,  kernel_size=(5,5),\n",
    "                                        strides=(1,1), padding='same')\n",
    "        self.deconv_4 = Conv2DTranspose(filters=64,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), padding='same')\n",
    "        self.deconv_4_1 = Conv2DTranspose(filters=64,  kernel_size=(5,5),\n",
    "                                        strides=(1,1), padding='same')\n",
    "        self.deconv_5 = Conv2DTranspose(filters=self.n_channels,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), padding='same')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.deconv_1(x)\n",
    "        x = self.deconv_1_1(x)\n",
    "        x = self.deconv_2(x)\n",
    "        x = self.deconv_2_1(x)\n",
    "        x = self.deconv_3(x)\n",
    "        x = self.deconv_3_1(x)\n",
    "        x = self.deconv_4(x)\n",
    "        x = self.deconv_4_1(x)\n",
    "        x = self.deconv_5(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        return tf.reduce_mean(x, axis=[1,2])\n",
    "        \n",
    "ae_model = Autoencoder(input_shape=x.shape[1:])\n",
    "y = ae_model(x)\n",
    "print(y.shape)\n",
    "z = ae_model.encode(x)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Functional)      (None, 2, 2, 2048)        23577344  \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran multiple                  2097408   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr multiple                  262400    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr multiple                  524416    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr multiple                  262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr multiple                  204864    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr multiple                  102464    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr multiple                  102464    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr multiple                  102464    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr multiple                  11207     \n",
      "=================================================================\n",
      "Total params: 27,247,303\n",
      "Trainable params: 27,201,863\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa7480fde0d49bfb399ae3de169b190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm.auto as tqdm\n",
    "mse_fn = tf.keras.losses.MeanSquaredError()\n",
    "optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "\n",
    "n_batches = x.shape[0] / 16\n",
    "\n",
    "pbar = tqdm.tqdm(enumerate(dataset))\n",
    "\n",
    "losses = []\n",
    "for i, batch in pbar:\n",
    "    with tf.GradientTape() as tape:\n",
    "        xout = ae_model(batch)\n",
    "        loss = mse_fn(batch, xout)\n",
    "    losses.append(loss.numpy())\n",
    "    grads = tape.gradient(loss, ae_model.trainable_variables)\n",
    "    optim.apply_gradients(zip(grads, ae_model.trainable_variables))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        pbar.set_description(f'mean loss = {np.mean(losses):3.3e}')\n",
    "        losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    x = tf.cast(x, tf.float32)/255.\n",
    "    return x\n",
    "    \n",
    "dataset = stream_dataset('tests/dataset.hdf5', use_channels=['DAPI', 'CD45', 'PanCytoK', 'CD31', 'PDGFRb', 'aSMA', 'Ki-67'],)\n",
    "dataset = dataset.map(process)\n",
    "\n",
    "z = []\n",
    "for batch in dataset:\n",
    "    z.append(ae_model.encode(batch).numpy().copy())\n",
    "    \n",
    "z = np.concatenate(z, axis=0)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('z.npy', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(ae_model, 'model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
