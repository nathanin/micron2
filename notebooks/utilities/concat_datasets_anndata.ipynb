{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import scrna\n",
    "import h5py\n",
    "\n",
    "from micron2 import load_as_anndata\n",
    "from micron2 import cluster_leiden_cu\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import time\n",
    "\n",
    "from micron2.data import staining_border_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "toss_1 = [f'TMA1_reg{x}_v5' for x in [1,3,11,21,22,23,24,27,35]]\n",
    "toss_2 = [f'TMA2_reg{x}_v5' for x in [2,3,14,15,16,20,21,22,23,24,26,34]]\n",
    "toss_3 = [f'TMA3_reg{x}_v5' for x in [1,2,7,8,14,15,20,21,23,25,31,32,33]]\n",
    "toss_patterns = toss_1 + toss_2 + toss_3\n",
    "def maybe_toss(x):\n",
    "    for p in toss_patterns:\n",
    "        if p in x:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = !ls -lha /storage/codex/preprocessed_data/*Bladder*/*_v5.hdf5 | awk '{print $9}'\n",
    "datasets = [d for d in datasets if 'reg0' not in d]\n",
    "datasets = [d for d in datasets if not maybe_toss(d)]\n",
    "print(len(datasets))\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-fiction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_channels = ['CD45', 'CD20', 'CD3e', 'CD45RO', 'CD45RA', 'CD8', 'CD4', 'CDH12', \n",
    "                 'KRT13', 'KRT17', 'PanCytoK', 'ERBB2']\n",
    "adatas = []\n",
    "sample_ids = []\n",
    "for path in datasets:\n",
    "    try:\n",
    "        ad = load_as_anndata(path, \n",
    "                             recover_tile_nuclei=False, \n",
    "                             as_sparse = False,\n",
    "                             features_dtype = None\n",
    "                            )\n",
    "    except:\n",
    "        print('failed to load', path)\n",
    "        continue\n",
    "    \n",
    "    # Apply staining border function\n",
    "    with h5py.File(ad.uns['source_data'], 'r') as h5f:\n",
    "        ncells = ad.shape[0]\n",
    "        h5_ncells = h5f['cells/DAPI'].shape[0]\n",
    "        print(ncells, h5_ncells)\n",
    "        ring_positive_pct = pd.DataFrame(index=ad.obs_names,\n",
    "                                         columns=[f'{ch}_ringpct' for ch in ring_channels],\n",
    "                                         dtype=np.float32\n",
    "                                        )\n",
    "        tstart = time.time()\n",
    "        for i in tqdm.trange(ncells):\n",
    "            m = h5f['meta/nuclear_masks'][i:i+1,:,:]\n",
    "            vect = []\n",
    "            for ch in ring_channels:\n",
    "                x = h5f[f'cells/{ch}'][i:i+1,:,:]\n",
    "                v = staining_border_nonzero(x,m)\n",
    "                vect.append(v)\n",
    "            ring_positive_pct.loc[ad.obs_names[i],:] = vect\n",
    "        tend = time.time()\n",
    "        print(f'elapsed time: {tend-tstart:3.4f}s')\n",
    "    ad.obs = pd.concat([ad.obs, ring_positive_pct], axis=1)\n",
    "\n",
    "    \n",
    "    adatas.append(ad.copy()) \n",
    "    s = os.path.splitext(os.path.basename(path))[0]\n",
    "    sample_ids.append(s)\n",
    "\n",
    "adata = adatas[0].concatenate(adatas[1:], batch_key='sample_id', batch_categories=sample_ids, \n",
    "                              index_unique = '-')\n",
    "print(sample_ids)\n",
    "adata.raw = adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ad in adatas:\n",
    "    print(ad.shape, ad.obs.shape)\n",
    "    df = ad.obs\n",
    "    ad.obs = ad.obs.loc[:, ~df.columns.duplicated()]\n",
    "    \n",
    "adata = adatas[0].concatenate(adatas[1:], batch_key='sample_id', batch_categories=sample_ids, \n",
    "                              index_unique = '-')\n",
    "print(sample_ids)\n",
    "adata.raw = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id_printing = ['\\n'.join(x.split('_')[2:4]) for x in adata.obs.sample_id]\n",
    "# sample_id_printing = [x.split('Breast_')[1].replace('_','\\n') for x in adata.obs.sample_id]\n",
    "adata.obs['sample_id_printing'] = sample_id_printing\n",
    "adata.uns['channels'] = ad.uns['channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lha /storage/codex/datasets_v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"/storage/codex/datasets_v1/bladder_merged.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lha /storage/codex/datasets_v1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-professional",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
