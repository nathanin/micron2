{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /storage/codex/v9/preprocessed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /storage/codex/v9/preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from micron2.data import pull_nuclei\n",
    "from micron2.data import load_as_anndata\n",
    "import pandas as pd\n",
    "import pytiff\n",
    "import glob\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "datahome = '/storage/codex/v9'\n",
    "sample_id = '210113_Breast_Cassette11_reg2'\n",
    "out_dir = '/storage/codex/datasets_v1'\n",
    "\n",
    "cells = pd.read_csv(f'{datahome}/preprocessed_output/{sample_id}/{sample_id}_2_centroids.csv', index_col=0, header=0)\n",
    "nuclei_img = f'{datahome}/preprocessed_output/{sample_id}/{sample_id}_2_nuclei.tif'\n",
    "\n",
    "# imagefs = !ls /home/ingn/tmp/micron2-data/rawdata/201021_BreastFFPE_Final/images/*.tif\n",
    "imagefs = sorted(glob.glob(f'{datahome}/preprocessed_data/{sample_id}/images/*.tif'))\n",
    "dapi_images = [f for f in imagefs if 'DAPI' in f]\n",
    "non_dapi_images = [f for f in imagefs if 'DAPI' not in f]\n",
    "non_dapi_images = [f for f in non_dapi_images if 'Blank' not in f]\n",
    "non_dapi_images = [f for f in non_dapi_images if 'Empty' not in f]\n",
    "\n",
    "channel_names = [os.path.basename(x) for x in non_dapi_images]\n",
    "channel_names = [x.replace(f'.tif','') for x in channel_names]\n",
    "channel_names = [x.split('_')[-2] for x in channel_names]\n",
    "channel_names = [\"DAPI\"] + channel_names\n",
    "print(len(channel_names))\n",
    "\n",
    "image_paths = [dapi_images[0]] + non_dapi_images\n",
    "print(len(image_paths))\n",
    "\n",
    "out_file = f'{out_dir}/{sample_id}.hdf5'\n",
    "\n",
    "pull_nuclei(cells, \n",
    "            image_paths, \n",
    "            out_file=out_file, \n",
    "            nuclei_img=nuclei_img,\n",
    "            size=64,\n",
    "            min_area=50, \n",
    "            tile_size=128,\n",
    "            channel_names=channel_names,\n",
    "            overlap=0.2,\n",
    "            tile_scale_factor=1.,\n",
    "            skip_tiles=True,\n",
    "            debug=False\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dapi_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open up the dataset as two AnnData objects: cells and tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default set to load the \"cell\" information\n",
    "adata_cells = load_as_anndata('/home/ingn/tmp/micron2-data/dataset_v2.hdf5')\n",
    "adata_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these to load the \"tile\" information\n",
    "adata_tiles = load_as_anndata('/home/ingn/tmp/micron2-data/dataset_v2.hdf5',\n",
    "                        obs_names='meta/Tile_IDs',\n",
    "                        featurekey='tile_intensity',\n",
    "                        coordkey='meta/tile_coordinates')\n",
    "adata_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test streaming from a dataset with tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micron2.data import stream_dataset\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream from the 'cells' group\n",
    "dataset = stream_dataset('/home/ingn/tmp/micron2-data/dataset_v2.hdf5', \n",
    "                         group_name='cells')\n",
    "\n",
    "for i, sample in enumerate(tqdm.tqdm(dataset)):\n",
    "    break\n",
    "\n",
    "print(i)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream from the 'images' group\n",
    "dataset = stream_dataset('/home/ingn/tmp/micron2-data/dataset_v2.hdf5', \n",
    "                         group_name='images')\n",
    "\n",
    "for i, sample in enumerate(tqdm.tqdm(dataset)):\n",
    "    break\n",
    "\n",
    "print(i)\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
