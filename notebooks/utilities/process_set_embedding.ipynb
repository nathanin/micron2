{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# Needs for RTX 3000 series cards running CUDA 11.0, cudnn 8.0.4, tensorflow 2.4 (2021-Jan-17)\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from micron2.embed_sets import SetEncoding, train_sets_SimCLR, stream_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/ingn/tmp/micron2-data/dataset_v2.hdf5\", \"r\") as h5f:\n",
    "    all_channels = [b.decode('utf-8') for b in h5f['meta/channel_names'][:]]\n",
    "    \n",
    "model = SetEncoding(inner_dim=256, outer_dim=128, g_dim=32, \n",
    "                    crop_size=48, # crop_size is for model set up only\n",
    "                    encoder_type='keras_resnet',\n",
    "                    n_channels=len(all_channels)\n",
    "                   )\n",
    "x = np.zeros((2, 6, 64, 64, len(all_channels)))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/ingn/tmp/micron2-data/single_moco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/ingn/tmp/micron2-data/single_moco/weights.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"/home/ingn/tmp/micron2-data/dataset_v2.hdf5\", \"r\") as h5f:\n",
    "    means = tf.constant([h5f[f'cell_intensity/{c}'].attrs['mean'] for c in all_channels], dtype=tf.float32)\n",
    "    stds =  tf.constant([h5f[f'cell_intensity/{c}'].attrs['std'] for c in all_channels], dtype=tf.float32)\n",
    "    \n",
    "# print(means, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm.auto as tqdm\n",
    "def process(x):\n",
    "    crop_pct = 48 / x.shape[1] \n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = tf.image.central_crop(x, crop_pct)\n",
    "    x = (x - means) / stds\n",
    "    return x\n",
    "    \n",
    "    \n",
    "zs = []\n",
    "with h5py.File(\"/home/ingn/tmp/micron2-data/dataset_v2.hdf5\", \"r\") as h5f:\n",
    "    coords = h5f['meta/cell_coordinates'][:]\n",
    "    streamer = stream_sets(h5f, coords=coords, use_channels=all_channels)\n",
    "    \n",
    "    batch = []\n",
    "    for i, x in enumerate(tqdm.tqdm(streamer)):\n",
    "        x = process(x)\n",
    "        batch.append(x)\n",
    "        if i % 8 == 0:\n",
    "            batch = tf.stack(batch, axis=0)\n",
    "            z = model(batch, training=False).numpy()\n",
    "            zs.append(z.copy())\n",
    "            batch = []\n",
    "            \n",
    "    # Process the leftover sample\n",
    "    batch = tf.stack(batch, axis=0)\n",
    "    z = model(batch, training=False).numpy()\n",
    "    zs.append(z.copy())\n",
    "        \n",
    "    \n",
    "zs = np.concatenate(zs, axis=0)\n",
    "print(zs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "MBKM = MiniBatchKMeans(n_clusters=20)\n",
    "groups = MBKM.fit_predict(zs)\n",
    "print(groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.dpi'] = 600\n",
    "for g in np.unique(groups):\n",
    "    i = groups == g\n",
    "    plt.scatter(coords[i,0], -coords[i,1], s=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
