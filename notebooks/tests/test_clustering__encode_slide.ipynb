{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from micron2.clustering import Autoencoder, train_AE_simCLR\n",
    "from micron2.data import stream_dataset\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "outdir = 'trained_simclr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'DAPI' b'OX40L' b'CD45' b'CD20' b'CD134' b'CD68' b'CD31' b'CD103'\n",
      " b'HLA-DR' b'CXCR5' b'IgG' b'CD3e' b'Ki-67' b'LAG3' b'CXCL13' b'IgA'\n",
      " b'CD89' b'PNaD' b'PD-L1' b'PD-1' b'CD11c' b'CD80' b'CD69' b'TIM3'\n",
      " b'CD45RO' b'CD40LG' b'FOXP3' b'CD64' b'GZMB' b'C1q' b'CD40' b'CD45RA'\n",
      " b'CD138' b'IL7R' b'IgM' b'PDGFRb' b'aSMA' b'CD8' b'CD4' b'PanCytoK']\n",
      "<KeysViewHDF5 ['cells', 'intensity', 'meta']>\n",
      "<KeysViewHDF5 ['C1q', 'CD103', 'CD11c', 'CD134', 'CD138', 'CD20', 'CD31', 'CD3e', 'CD4', 'CD40', 'CD40LG', 'CD45', 'CD45RA', 'CD45RO', 'CD64', 'CD68', 'CD69', 'CD8', 'CD80', 'CD89', 'CXCL13', 'CXCR5', 'DAPI', 'FOXP3', 'GZMB', 'HLA-DR', 'IL7R', 'IgA', 'IgG', 'IgM', 'Ki-67', 'LAG3', 'OX40L', 'PD-1', 'PD-L1', 'PDGFRb', 'PNaD', 'PanCytoK', 'TIM3', 'aSMA']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File('/dev/shm/dataset.hdf5', 'r')\n",
    "print(f['meta/channel_names'][:])\n",
    "use_channels = [b.decode('UTF-8') for b in f['meta/channel_names'][:]]\n",
    "# fn = lambda x,y: print(x)\n",
    "print(f.keys())\n",
    "print(f['cells'].keys())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ing/miniconda3/envs/micron2/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 40 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 64, 64, 40)\n",
      "(8, 32)\n",
      "(8, 256)\n"
     ]
    }
   ],
   "source": [
    "sample_x = tf.zeros((8, 64, 64, len(use_channels)), dtype=tf.float32)\n",
    "ae_model = Autoencoder(input_shape=sample_x.shape[1:])\n",
    "y, z_g = ae_model(sample_x, return_g=True)\n",
    "print(y.shape)\n",
    "print(z_g.shape)\n",
    "z = ae_model.encode(sample_x)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model.load_weights(f'{outdir}/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8e768ebeb24dd3bbbc8c8e97ec2cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(146791, 32)\n",
      "0\n",
      "(146791, 256)\n",
      "187\n"
     ]
    }
   ],
   "source": [
    "def process(x):\n",
    "    x = tf.cast(x, tf.float32)/255.\n",
    "    x = tf.transpose(tf.image.per_image_standardization(tf.transpose(x)))\n",
    "    return x\n",
    "    \n",
    "# use_channels=['DAPI', 'CD45', 'PanCytoK']\n",
    "# use_channels=['DAPI', 'CD45', 'PanCytoK', 'CD31', 'PDGFRb', 'aSMA', 'Ki-67']\n",
    "dataset = stream_dataset('/dev/shm/dataset.hdf5', use_channels = use_channels)\n",
    "dataset = (dataset.map(process)\n",
    "           .batch(64)\n",
    "          )\n",
    "\n",
    "z = []\n",
    "z_L2 = []\n",
    "for batch in tqdm.tqdm(dataset):\n",
    "    # batch = tf.image.random_crop(batch, size=(batch.shape[0], 48, 48, batch.shape[-1]))\n",
    "    z.append(ae_model.encode_g(batch).numpy().copy())\n",
    "    z_L2.append(ae_model.encode(batch).numpy().copy())\n",
    "    \n",
    "z = np.concatenate(z, axis=0)\n",
    "z_L2 = np.concatenate(z_L2, axis=0)\n",
    "print(z.shape)\n",
    "print((z.sum(0)==0).sum())\n",
    "\n",
    "print(z_L2.shape)\n",
    "print((z_L2.sum(0)==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{outdir}/z.npy', z)\n",
    "np.save(f'{outdir}/z_L2.npy', z_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 275M\r\n",
      "drwxrwxr-x 2 ing ing 4.0K Nov 16 22:32 .\r\n",
      "drwxrwxr-x 4 ing ing 4.0K Nov 17 09:13 ..\r\n",
      "-rw-rw-r-- 1 ing ing 114M Nov 17 05:22 weights.h5\r\n",
      "-rw-rw-r-- 1 ing ing 144M Nov 17 09:20 z_L2.npy\r\n",
      "-rw-rw-r-- 1 ing ing  18M Nov 17 09:20 z.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lha trained_simclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
