{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytiff\n",
    "import h5py\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /mnt/linux-data/codex/preprocessed_data/201021_BreastFFPE_Final/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = pd.read_csv('/mnt/linux-data/codex/preprocessed_data/201021_BreastFFPE_Final/201021_BreastFFPE_Final_3_cells.csv', \n",
    "                    index_col=0, header=0)\n",
    "cells.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagefs = !ls /mnt/linux-data/codex/preprocessed_data/201021_BreastFFPE_Final/images/*.tif\n",
    "dapi_images = [f for f in imagefs if 'DAPI' in f]\n",
    "non_dapi_images = [f for f in imagefs if 'DAPI' not in f]\n",
    "non_dapi_images = [f for f in non_dapi_images if 'Blank' not in f]\n",
    "non_dapi_images = [f for f in non_dapi_images if 'Empty' not in f]\n",
    "for f in non_dapi_images:\n",
    "    print(os.path.basename(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPT_NAME = '201021_BreastFFPE_Final'\n",
    "channel_names = [os.path.basename(x) for x in non_dapi_images]\n",
    "# channel_names = [x.replace(f'{EXPT_NAME}_','') for x in channel_names]\n",
    "channel_names = [x.replace(f'.tif','') for x in channel_names]\n",
    "channel_names = [x.split('_')[-2] for x in channel_names]\n",
    "# channel_names = [x.replace('-', '_') for x in channel_names]\n",
    "channel_names = [\"DAPI\"] + channel_names\n",
    "print( channel_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [dapi_images[0]] + non_dapi_images\n",
    "print(len(image_paths))\n",
    "# image_handles = [pytiff.Tiff(dapi_images[0])] + [pytiff.Tiff(f) for f in non_dapi_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(cells.Size, bins=100)\n",
    "np.quantile(cells.Size, [0.01, 0.1, 0.9, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "\n",
    "def pull_nuclei(coords, image_paths, out_file='dataset.hdf5', size=64, min_area=100, channel_names=None):\n",
    "    h0 = pytiff.Tiff(image_paths[0])\n",
    "    sizeh = int(size/2)\n",
    "    h, w = h0.shape\n",
    "    print(h, w)\n",
    "    maxh = h - sizeh\n",
    "    maxw = w - sizeh\n",
    "    h0.close()\n",
    "    \n",
    "    if channel_names is None:\n",
    "        channel_names = [f'ch{i:02d}' for i in range(len(image_paths))]\n",
    "    assert len(channel_names) == len(image_paths)\n",
    "    \n",
    "    h5f = h5py.File(out_file, \"w\")\n",
    "    \n",
    "    datasets = []\n",
    "    for c in channel_names:\n",
    "        d = h5f.create_dataset(f'cells/{c}', shape=(coords.shape[0],size,size), maxshape=(None,size,size),\n",
    "                               dtype='i', chunks=(1,size,size), compression='gzip')\n",
    "        datasets.append(d)\n",
    "        \n",
    "    # remove coords too near the edges:\n",
    "    # remember, x = \"width\" = size[1]; y = \"height\" = size[0]\n",
    "    coords = coords.query(\"X > @sizeh & X < @maxw & Y > @sizeh & Y < @maxh\")\n",
    "    if min_area is not None:\n",
    "        coords = coords.query(\"Size > @min_area\")\n",
    "    \n",
    "    print(f'Pulling {coords.shape[0]} cells')\n",
    "    for pth, d, c in zip(image_paths, datasets, channel_names):\n",
    "        print(f'Pulling from channel {c}')\n",
    "        h = pytiff.Tiff(pth)\n",
    "        page = h.pages[0][:]\n",
    "        \n",
    "        i = 0\n",
    "        for x, y in tqdm(zip(coords.X, coords.Y)):\n",
    "            # print(x, y, a)\n",
    "            bbox = [y-sizeh, y+sizeh, x-sizeh, x+sizeh]\n",
    "            img = (255 * (page[bbox[0]:bbox[1], bbox[2]:bbox[3]] / 2**16)).astype(np.uint8)\n",
    "            # img = [255 * (h.pages[0][bbox[0]:bbox[1], bbox[2]:bbox[3]] / 2**16).astype(np.uint8) for h in image_handles]\n",
    "            # print(np.mean(img))\n",
    "            # xout[i, :, :, :] = np.dstack(img)\n",
    "            d[i,...] = img\n",
    "\n",
    "            i += 1\n",
    "            # if i > 5000: \n",
    "            #     break\n",
    "        h.close()\n",
    "        h5f.flush()\n",
    "    h5f.close()\n",
    "\n",
    "pull_nuclei(cells, image_paths, out_file='dataset.hdf5', min_area=100, channel_names=channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
