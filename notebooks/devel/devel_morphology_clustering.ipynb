{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from micron2.data import stream_dataset\n",
    "\n",
    "import tqdm.auto as tqdm\n",
    "\n",
    "from tensorflow.keras.layers import (Dense, Conv2D, Dropout, BatchNormalization, Conv2DTranspose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('/dev/shm/dataset.hdf5', 'r')\n",
    "print(f['meta/channel_names'][:])\n",
    "use_channels = [b.decode('UTF-8') for b in f['meta/channel_names'][:]]\n",
    "# fn = lambda x,y: print(x)\n",
    "print(f.keys())\n",
    "print(f['cells'].keys())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = load_dataset('tests/dataset.hdf5', use_channels=['DAPI', 'CD45', 'PanCytoK', 'CD31', 'PDGFRb', 'aSMA', 'Ki-67'],\n",
    "#                  verbose=True)\n",
    "# print(x.shape)\n",
    "\n",
    "print(use_channels)\n",
    "def process(x):\n",
    "    x = tf.cast(x, tf.float32)/255.\n",
    "    return x\n",
    "    \n",
    "dataset = stream_dataset('/dev/shm/dataset.hdf5', use_channels=use_channels)\n",
    "dataset = (dataset.repeat(10)\n",
    "           .shuffle(1024 * 6)\n",
    "           .map(process)\n",
    "           .batch(16)\n",
    "           .prefetch(8)\n",
    "           #.apply(tf.data.experimental.prefetch_to_device(\"/gpu:0\"))\n",
    "          )\n",
    "\n",
    "for sample_x in dataset:\n",
    "    break\n",
    "    \n",
    "print(sample_x.shape)\n",
    "for k in range(sample_x.shape[-1]):\n",
    "    print(sample_x.numpy()[...,k].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_shape=[64, 64, 3]):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.n_channels = input_shape[-1]\n",
    "        self.n_upsamples = 7\n",
    "        self.conv_1 = tf.keras.applications.ResNet50V2(include_top=False, weights=None,\n",
    "                                                       input_shape=input_shape,\n",
    "                                                       pooling='average')\n",
    "        self.conv_2 = Conv2D(filters=256, kernel_size=(2,2), strides=(1,1), \n",
    "                             padding='same', activation='relu')\n",
    "        \n",
    "        self.g_fn = Dense(32, activation=None, name='g_simclr')\n",
    "        \n",
    "        self.build_upsample(name='up_large')\n",
    "        self.build_upsample(name='up_small')\n",
    "        \n",
    "    def build_upsample(self, name='upsample'):\n",
    "        p_act = dict(padding='same', activation='relu')\n",
    "        setattr(self, f'{name}_0', Conv2DTranspose(filters=256,  kernel_size=(2,2),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_1', Conv2DTranspose(filters=128,  kernel_size=(3,3),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_2', Conv2DTranspose(filters=64,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_3', Conv2DTranspose(filters=64,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_4', Conv2DTranspose(filters=64,  kernel_size=(3,3),\n",
    "                                        strides=(1,1), **p_act))\n",
    "        setattr(self, f'{name}_5', Conv2DTranspose(filters=self.n_channels,  kernel_size=(5,5),\n",
    "                                        strides=(2,2), **p_act))\n",
    "        setattr(self, f'{name}_6', Conv2DTranspose(filters=self.n_channels,  kernel_size=(3,3),\n",
    "                                        strides=(1,1), **p_act))\n",
    "        \n",
    "    def apply_upsample(self, z, name='upsample'):\n",
    "        for j in range(self.n_upsamples):\n",
    "            z = getattr(self, f'{name}_{j}')(z)\n",
    "        return z\n",
    "        \n",
    "    def call(self, x, return_g=False):\n",
    "        x1 = self.conv_1(x)\n",
    "        x2 = self.conv_2(x1)\n",
    "        \n",
    "        # Two parallel upsampling paths\n",
    "        x1u = self.apply_upsample(x1, name='up_large')\n",
    "        x2u = self.apply_upsample(x2, name='up_small')\n",
    "\n",
    "        xout = tf.reduce_mean([x1u, x2u], axis=0)\n",
    "        xout = tf.image.resize_with_crop_or_pad(xout, x.shape[1], x.shape[2])\n",
    "        if return_g:\n",
    "            g = self.g_fn(tf.reduce_mean(x2, axis=[1,2]))\n",
    "            return xout, g\n",
    "        return xout  \n",
    "    \n",
    "    def encode_g(self, x):\n",
    "        # Apply g function for simclr\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = tf.reduce_mean(x, axis=[1,2])\n",
    "        x = self.g_fn(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x, retval=1):\n",
    "        if retval == 0:\n",
    "            x = self.conv_1(x)\n",
    "        elif retval == 1:\n",
    "            x = self.conv_1(x)\n",
    "            x = self.conv_2(x)\n",
    "            \n",
    "        return tf.reduce_mean(x, axis=[1,2])\n",
    "        \n",
    "sample_x = tf.image.random_crop(sample_x, size=(sample_x.shape[0], 48, 48, sample_x.shape[-1]))\n",
    "ae_model = Autoencoder(input_shape=sample_x.shape[1:])\n",
    "y = ae_model(sample_x)\n",
    "print(y.shape)\n",
    "z = ae_model.encode(sample_x)\n",
    "print(z.shape)\n",
    "z_g = ae_model.encode_g(sample_x)\n",
    "print(z_g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal training -- autoencoder only\n",
    "def train_loop(dataset, model):\n",
    "    mse_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "\n",
    "    pbar = tqdm.tqdm(enumerate(dataset))\n",
    "\n",
    "    losses = []\n",
    "    for i, batch in pbar:\n",
    "        with tf.GradientTape() as tape:\n",
    "            xout = model(batch)\n",
    "            loss = mse_fn(batch, xout)\n",
    "        losses.append(loss.numpy())\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optim.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            pbar.set_description(f'mean loss = {np.mean(losses):3.5e}')\n",
    "            losses = []\n",
    "            \n",
    "train_loop(dataset, ae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder only but with gradient accumulation\n",
    "def train_loop_grad_accum(dataset, model):\n",
    "    mse_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    pbar = tqdm.tqdm(enumerate(dataset))\n",
    "    losses = []\n",
    "    grad_dict = {v.name: [] for v in model.trainable_variables}\n",
    "    \n",
    "    def stash_grads(grads, grad_dict, trainable_variables):\n",
    "        for i, v in enumerate(trainable_variables):\n",
    "            grad_dict[v.name].append(grads[i])\n",
    "    \n",
    "    def mean_grads(grad_dict, trainable_variables):\n",
    "        grads = [tf.reduce_mean(grad_dict[v.name], axis=0) for v in trainable_variables]\n",
    "        return grads\n",
    "    \n",
    "    for i, batch in pbar:\n",
    "        with tf.GradientTape() as tape:\n",
    "            xout = model(batch)\n",
    "            loss = mse_fn(batch, xout)\n",
    "        losses.append(loss.numpy())\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        \n",
    "        stash_grads(grads, grad_dict, model.trainable_variables)\n",
    "        if i % 32 == 0:\n",
    "            grads = mean_grads(grad_dict, model.trainable_variables)\n",
    "            optim.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            grad_dict = {v.name: [] for v in model.trainable_variables}\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            pbar.set_description(f'mean loss = {np.mean(losses):3.5e}')\n",
    "            losses = []\n",
    "            \n",
    "train_loop_grad_accum(dataset, ae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(u, tau=1.0):\n",
    "    nu = tf.norm(u, ord=2, keepdims=True, axis=-1)\n",
    "    sim = tf.tensordot(u, tf.transpose(u), 1) \n",
    "    return sim / (tf.constant(1e-9) + (tau * nu * tf.transpose(nu)))\n",
    "\n",
    "\n",
    "def simclr_loss_fn(z_i, tau=1.):\n",
    "    \"\"\"\n",
    "    A Simple Framework for Contrastive learning of Visual Representations\n",
    "    Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, 2020.  \n",
    "    https://arxiv.org/abs/2002.05709\n",
    "    \"\"\"\n",
    "\n",
    "    s = tf.exp(similarity(z_i, tau=tau))\n",
    "    i_part, j_part = tf.split(s, 2, 0)\n",
    "\n",
    "    total_i = tf.reduce_sum(i_part, axis=-1) - tf.linalg.diag_part(i_part)\n",
    "    total_j = tf.reduce_sum(j_part, axis=-1) - tf.linalg.diag_part(j_part)\n",
    "\n",
    "    l_i = -tf.math.log( tf.linalg.diag_part(i_part) / total_i )\n",
    "    l_j = -tf.math.log( tf.linalg.diag_part(j_part) / total_j )\n",
    "\n",
    "    loss = tf.reduce_sum(l_i + l_j)\n",
    "    return loss\n",
    "    \n",
    "\n",
    "def perturb_x(x):\n",
    "    x = tf.image.random_crop(x, size=(x.shape[0], 48, 48, x.shape[-1]))\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "# Autoencoder + simCLR. Use gradient accumulation for simCLR loss. \n",
    "# Autoencoder is trained every step\n",
    "def train_AE_simCLR(dataset, model):\n",
    "    mse_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    simclr_optim = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    pbar = tqdm.tqdm(enumerate(dataset))\n",
    "    losses, sc_losses = [], []\n",
    "    prev_loss, prev_sc_loss = 0, 0\n",
    "    \n",
    "    def stash_grads(grads, grad_dict, trainable_variables):\n",
    "        for i, v in enumerate(trainable_variables):\n",
    "            if grads[i] is None:\n",
    "                grad_dict[v.name].append(tf.zeros(v.shape, dtype=tf.float32))\n",
    "            else:\n",
    "                grad_dict[v.name].append(grads[i])\n",
    "    \n",
    "    def mean_grads(grad_dict, trainable_variables):\n",
    "        grads = [tf.reduce_mean(grad_dict[v.name], axis=0) for v in trainable_variables]\n",
    "        return grads\n",
    "    \n",
    "    # Grab variables for the AE portion because otherwise theres tons of warnings\n",
    "    ae_vars = [v for v in ae_model.trainable_variables if 'g_simclr' not in v.name]\n",
    "    \n",
    "    grad_dict = {v.name: [] for v in model.trainable_variables}\n",
    "    for i, batch in pbar:\n",
    "        batch_in = tf.image.random_crop(batch, size=(batch.shape[0], 48, 48, batch.shape[-1]))\n",
    "        batch_p = perturb_x(batch)\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            xout1, g1 = model(batch_in, return_g=True)\n",
    "            xout2, g2 = model(batch_p, return_g=True)\n",
    "            \n",
    "            mse_loss = mse_fn(tf.concat([batch_in, batch_p], axis=0), \n",
    "                              tf.concat([xout1, xout2], axis=0))\n",
    "            l_simclr = simclr_loss_fn(tf.concat([g1, g2], axis=0), tau=0.1)\n",
    "            \n",
    "        losses.append(mse_loss.numpy())\n",
    "        sc_losses.append(l_simclr.numpy())\n",
    "        mse_grads = tape.gradient(mse_loss, ae_vars)\n",
    "        simclr_grads = tape.gradient(l_simclr, model.trainable_variables)\n",
    "        del tape\n",
    "        \n",
    "        optim.apply_gradients(zip(mse_grads, ae_vars))\n",
    "        stash_grads(simclr_grads, grad_dict, model.trainable_variables)\n",
    "        if i % 16 == 0:\n",
    "            simclr_grads = mean_grads(grad_dict, model.trainable_variables)\n",
    "            simclr_optim.apply_gradients(zip(simclr_grads, model.trainable_variables))\n",
    "            grad_dict = {v.name: [] for v in model.trainable_variables}\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            m_loss = np.mean(losses)\n",
    "            m_sc_losses = np.mean(sc_losses)\n",
    "            #pbar.set_description(f'mse_loss = {np.mean(losses):3.5e} simclr_loss = {np.mean(sc_losses):3.5e}')\n",
    "            pbar.set_description(f'd(mse_loss) = {prev_loss-m_loss:3.5e}\\td(simclr_loss) = {prev_sc_loss-m_sc_losses:3.5e}')\n",
    "            prev_loss = np.mean([prev_loss, m_loss])\n",
    "            prev_sc_loss = np.mean([prev_sc_loss, m_sc_losses])\n",
    "            losses, sc_losses = [], []\n",
    "            \n",
    "train_AE_simCLR(dataset, ae_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    # x = tf.image.random_crop(x, size=(x.shape[0], 48, 48, x.shape[-1]))\n",
    "    x = tf.cast(x, tf.float32)/255.\n",
    "    return x\n",
    "    \n",
    "# use_channels=['DAPI', 'CD45', 'PanCytoK']\n",
    "# use_channels=['DAPI', 'CD45', 'PanCytoK', 'CD31', 'PDGFRb', 'aSMA', 'Ki-67']\n",
    "dataset = stream_dataset('tests/dataset.hdf5', use_channels = use_channels)\n",
    "dataset = (dataset.map(process)\n",
    "           .batch(64)\n",
    "          )\n",
    "\n",
    "z = []\n",
    "for batch in tqdm.tqdm(dataset):\n",
    "    z.append(ae_model.encode_g(batch).numpy().copy())\n",
    "    \n",
    "z = np.concatenate(z, axis=0)\n",
    "print(z.shape)\n",
    "print((z.sum(0)==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'simclr_model'\n",
    "np.save(f'{outdir}/z.npy', z)\n",
    "ae_model.save_weights(f\"{outdir}/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "sample_xout = ae_model(sample_x)\n",
    "for j in range(sample_x.shape[-1]):\n",
    "    print(f'channel {j}\\t' +\\\n",
    "          f'pred {tf.reduce_sum(sample_xout[...,j]).numpy():<4.2f}\\t' +\\\n",
    "          f'real {tf.reduce_sum(sample_x[...,j]).numpy():<4.2f}')\n",
    "\n",
    "idx = np.random.choice(sample_xout.shape[0])\n",
    "jdx = np.random.choice(sample_xout.shape[-1])\n",
    "\n",
    "jdx = 0\n",
    "\n",
    "print(idx, jdx)\n",
    "sx = sample_x.numpy()[idx, :,:, jdx]\n",
    "sxout = sample_xout.numpy()[idx, :,:, jdx] \n",
    "print(jdx, sx.sum(), sxout.sum())\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(sx)# / sx.max())\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(sxout)# / sxout.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
